"""
AI-102 Azure AI Vision Unified Demo
===================================

Comprehensive demonstration of Azure AI Vision services for AI-102 exam preparation.
Combines Image Analysis, OCR, and Face Detection with both educational and real API modes.

Features:
- Educational mode: Perfect for presentations and learning
- Production mode: Uses real Face API when credentials are available
- Automatic fallback: If Face API not configured, uses educational content
"""

import os
import sys
from dotenv import load_dotenv
from azure.core.credentials import AzureKeyCredential


def print_header():
    """Print demo header"""
    print("=" * 80)
    print("ğŸ¯ AI-102 Azure AI Vision Demo")
    print("=" * 80)
    print("\nğŸ¢ Story: Smart Office Security System")
    print("Demonstrating three Azure AI Vision services:")
    print("1ï¸âƒ£  Image Analysis - Scene understanding")
    print("2ï¸âƒ£  OCR - Text extraction from images")
    print("3ï¸âƒ£  Face Analysis - Face detection & attributes")
    print("\n" + "=" * 80)


def check_face_api_available():
    """Check if Face API credentials are configured"""
    try:
        load_dotenv()
        face_endpoint = os.getenv('FACE_ENDPOINT')
        face_key = os.getenv('FACE_KEY')
        
        if face_endpoint and face_key:
            # Try to import Face SDK
            from azure.ai.vision.face import FaceClient
            return True
        return False
    except ImportError:
        return False
    except Exception:
        return False


def demo_image_analysis():
    """Demo 1: Image Analysis with real Computer Vision API"""
    print("\nğŸ“– CHAPTER 1: IMAGE ANALYSIS")
    print("=" * 60)
    print("ğŸ¬ Scenario: Visitor enters office lobby")
    print("ğŸ¤– AI Task: Analyze scene and detect objects/people")
    print("ğŸ” Analyzing: street.jpg")
    
    try:
        from azure.cognitiveservices.vision.computervision import ComputerVisionClient
        from msrest.authentication import CognitiveServicesCredentials
        load_dotenv()
        
        # Get Computer Vision credentials
        cv_endpoint = os.getenv('COMPUTER_VISION_ENDPOINT')
        cv_key = os.getenv('COMPUTER_VISION_KEY')
        
        if not cv_endpoint or not cv_key:
            print("âŒ Computer Vision credentials not found, using educational mode")
            demo_image_analysis_educational()
            return
            
        # Initialize Computer Vision client
        cv_credentials = CognitiveServicesCredentials(cv_key)
        cv_client = ComputerVisionClient(cv_endpoint, cv_credentials)
        
        # Use the actual image from the local images folder
        image_path = "images/street.jpg"
        
        # Real Computer Vision API call
        with open(image_path, "rb") as image_data:
            analysis = cv_client.analyze_image_in_stream(
                image_data,
                visual_features=[
                    'Categories', 'Description', 'Objects', 'Tags', 'Adult'
                ]
            )
        
        # Display real results
        if analysis.description.captions:
            caption = analysis.description.captions[0]
            confidence = caption.confidence * 100
            print(f"\nğŸ·ï¸  CAPTION: '{caption.text}'")
            print(f"   Confidence: {confidence:.1f}%")
        
        if analysis.tags:
            print("\nğŸ·ï¸  TOP TAGS:")
            for tag in analysis.tags[:5]:
                confidence = tag.confidence * 100
                print(f"   â€¢ {tag.name} ({confidence:.1f}%)")
        
        if analysis.objects:
            print(f"\nğŸ“¦ OBJECTS: Found {len(analysis.objects)}")
            for obj in analysis.objects[:5]:
                confidence = obj.confidence * 100
                print(f"   â€¢ {obj.object_property} ({confidence:.1f}%)")
        
        # Count people in objects
        people_count = sum(1 for obj in analysis.objects
                          if 'person' in obj.object_property.lower())
        print(f"\nï¿½ PEOPLE: Detected {people_count}")
        
        print("\nâœ… Real Computer Vision API working!")
        
    except FileNotFoundError:
        print(f"\nâŒ Image file not found: {image_path}")
        demo_image_analysis_educational()
    except Exception as e:
        print(f"\nâŒ Computer Vision API Error: {str(e)}")
        demo_image_analysis_educational()
    
    print("\nğŸ’¡ AI-102 KEY CONCEPTS:")
    print("   ğŸ¯ Visual Features: Choose analysis type (caption, tags, objects)")
    print("   ğŸ“Š Confidence Scores: 0.0 to 1.0 reliability measure")
    print("   ğŸ“ Bounding Boxes: Object locations (x, y, width, height)")
    print("   âš¡ Synchronous Processing: Real-time analysis")


def demo_image_analysis_educational():
    """Fallback educational mode for image analysis"""
    print("\nğŸ·ï¸  CAPTION: 'a man walking a dog on a leash'")
    print("   Confidence: 83.1%")
    
    print("\nğŸ·ï¸  TOP TAGS:")
    print("   â€¢ outdoor (99.9%)")
    print("   â€¢ land vehicle (98.9%)")
    print("   â€¢ vehicle (98.8%)")
    print("   â€¢ building (98.3%)")
    print("   â€¢ road (96.8%)")
    
    print("\nğŸ“¦ OBJECTS: Found 4")
    print("   â€¢ car (79.7%)")
    print("   â€¢ taxi (79.3%)")
    print("   â€¢ person (79.1%)")
    
    print("\nğŸ‘¥ PEOPLE: Detected 1")
    
    print("\nğŸ’¡ Educational Mode: Computer Vision API not configured")
    print("   âš¡ Synchronous Processing: Real-time analysis")


def demo_ocr():
    """Demo 2: OCR Text Extraction with real Computer Vision API"""
    print("\nğŸ“– CHAPTER 2: OCR (OPTICAL CHARACTER RECOGNITION)")
    print("=" * 60)
    print("ğŸ¬ Scenario: Security badge scanner at entrance")
    print("ğŸ¤– AI Task: Extract text from visitor's ID badge")
    print("ğŸ” Analyzing: Business-card.jpg")
    
    try:
        from azure.cognitiveservices.vision.computervision import ComputerVisionClient
        from msrest.authentication import CognitiveServicesCredentials
        import time
        load_dotenv()
        
        # Get Computer Vision credentials
        cv_endpoint = os.getenv('COMPUTER_VISION_ENDPOINT')
        cv_key = os.getenv('COMPUTER_VISION_KEY')
        
        if not cv_endpoint or not cv_key:
            print("âŒ Computer Vision credentials not found, using educational mode")
            demo_ocr_educational()
            return
            
        # Initialize Computer Vision client
        cv_credentials = CognitiveServicesCredentials(cv_key)
        cv_client = ComputerVisionClient(cv_endpoint, cv_credentials)
        
        # Use the actual image from the local images folder
        image_path = "images/Business-card.jpg"
        
        # Real OCR API call using Read API
        with open(image_path, "rb") as image_data:
            read_operation = cv_client.read_in_stream(image_data, raw=True)
        
        # Get operation ID from headers
        operation_id = read_operation.headers["Operation-Location"].split("/")[-1]
        
        # Poll for results
        print("   Processing text extraction...")
        while True:
            result = cv_client.get_read_result(operation_id)
            if result.status not in ['notStarted', 'running']:
                break
            time.sleep(1)
        
        # Display real results
        if result.status == 'succeeded':
            print("\nğŸ“ EXTRACTED TEXT:")
            line_num = 1
            for page in result.analyze_result.read_results:
                for line in page.lines:
                    confidence = getattr(line, 'confidence', 0.95) * 100
                    print(f"   Line {line_num}: '{line.text}' "
                          f"(confidence: {confidence:.1f}%)")
                    line_num += 1
                    if line_num > 6:  # Limit output for demo
                        break
        else:
            print(f"\nâŒ OCR failed with status: {result.status}")
            demo_ocr_educational()
            return
        
        print("\nâœ… Real OCR API working!")
        
    except FileNotFoundError:
        print(f"\nâŒ Image file not found: {image_path}")
        demo_ocr_educational()
    except Exception as e:
        print(f"\nâŒ OCR API Error: {str(e)}")
        demo_ocr_educational()
    
    print("\nğŸ’¡ AI-102 KEY CONCEPTS:")
    print("   ğŸ“– Read API: Best for documents and printed text")
    print("   ğŸ”„ Async Processing: For large documents")
    print("   ğŸŒ Language Detection: 73+ languages supported")
    print("   ğŸ“ Bounding Polygons: Exact text location coordinates")


def demo_ocr_educational():
    """Fallback educational mode for OCR"""
    print("\nğŸ“ EXTRACTED TEXT:")
    print("   Line 1: 'Dr. Sarah Chen' (confidence: 99.8%)")
    print("   Line 2: 'Senior Data Scientist' (confidence: 99.5%)")
    print("   Line 3: 'Microsoft Corporation' (confidence: 99.9%)")
    print("   Line 4: 'sarah.chen@microsoft.com' (confidence: 98.7%)")
    
    print("\nğŸ’¡ Educational Mode: Computer Vision API not configured")
    print("   ğŸ“ Bounding Polygons: Exact text location coordinates")


def demo_face_analysis():
    """Demo 3: Face Analysis - Auto-detects API availability"""
    print("\nğŸ“– CHAPTER 3: FACE ANALYSIS")
    print("=" * 60)
    print("ğŸ¬ Scenario: Facial recognition access control")
    print("ğŸ¤– AI Task: Detect faces and analyze attributes")
    
    # Check if real Face API is available
    if check_face_api_available():
        print("ğŸ” Using REAL Face API")
        demo_face_analysis_real()
    else:
        print("ğŸ” Using EDUCATIONAL mode (Face API not configured)")
        demo_face_analysis_educational()


def demo_face_analysis_real():
    """Real Face API demonstration"""
    try:
        from azure.ai.vision.face import FaceClient
        load_dotenv()
        
        face_endpoint = os.getenv('FACE_ENDPOINT')
        face_key = os.getenv('FACE_KEY')
        
        face_client = FaceClient(
            endpoint=face_endpoint,
            credential=AzureKeyCredential(face_key)
        )
        
        print("ğŸ” Analyzing: people.jpg")
        
        # Use the actual image from the local images folder
        image_path = "images/people.jpg"
        
        # Real Face API call - basic face detection only
        # Note: Advanced features require Microsoft approval
        with open(image_path, "rb") as image_data:
            detected_faces = face_client.detect(
                image_data,
                detection_model="detection_03",
                recognition_model="recognition_04",
                return_face_id=False,
                return_face_attributes=["glasses", "headPose"],
                return_face_landmarks=True
            )
        
        print("\nğŸ‘¤ FACE DETECTION RESULTS:")
        print(f"   Faces detected: {len(detected_faces)}")
        
        for i, face in enumerate(detected_faces, 1):
            rect = face.face_rectangle
            attrs = face.face_attributes
            
            print("   ")
            print(f"   Face {i}:")
            print(f"   â€¢ Glasses: {attrs.glasses}")
            
            # Head pose information
            head_pose = attrs.head_pose
            print(f"   â€¢ Head Yaw: {head_pose.yaw:.1f}Â° "
                  f"(left/right turn)")
            
            coords = f"{rect.left}, {rect.top}, {rect.width}, {rect.height}"
            print(f"   â€¢ Location: ({coords})")
            
            # Show key landmarks if available
            if face.face_landmarks:
                landmarks = face.face_landmarks
                nose_tip = landmarks.nose_tip
                print(f"   â€¢ Nose Tip: ({nose_tip.x:.0f}, {nose_tip.y:.0f})")
                
                left_eye = landmarks.pupil_left
                right_eye = landmarks.pupil_right
                print(f"   â€¢ Eyes: Left({left_eye.x:.0f}, {left_eye.y:.0f}), "
                      f"Right({right_eye.x:.0f}, {right_eye.y:.0f})")
        
        print("\nâœ… Real Face API working!")
        
        print("\nğŸ’¡ AI-102 KEY CONCEPTS:")
        print("   ğŸ‘¤ Face Detection: Locate faces in images")
        print("   ğŸ“Š Face Attributes: Age, gender, emotion, accessories")
        print("   ğŸ“ Face Rectangle: Bounding box coordinates")
        print("   ğŸ”’ Privacy: Face detection â‰  face recognition")
        print("   âš–ï¸ Compliance: Follow responsible AI guidelines")
        
    except FileNotFoundError:
        print(f"\nâŒ Image file not found: {image_path}")
        print("   Using sample data for demonstration...")
        demo_face_analysis_educational()
    except Exception as e:
        print(f"\nâŒ Face API Error: {str(e)}")
        print("   Falling back to educational mode...")
        demo_face_analysis_educational()


def demo_face_analysis_educational():
    """Educational face analysis demonstration"""
    print("ğŸ” Analyzing: people.jpg")
    
    print("\nğŸ‘¤ FACE DETECTION RESULTS (Simulated):")
    print("   Faces detected: 2")
    print("   ")
    print("   Face 1:")
    print("   â€¢ Age: 32 Â± 5 years")
    print("   â€¢ Gender: Female")
    print("   â€¢ Emotion: Happy (85.2%)")
    print("   â€¢ Glasses: None")
    print("   â€¢ Location: (145, 67, 120, 160)")
    print("   ")
    print("   Face 2:")
    print("   â€¢ Age: 28 Â± 4 years")
    print("   â€¢ Gender: Male")
    print("   â€¢ Emotion: Neutral (76.8%)")
    print("   â€¢ Glasses: Reading")
    print("   â€¢ Location: (289, 73, 115, 154)")
    
    print("\nğŸ’¡ AI-102 KEY CONCEPTS:")
    print("   ğŸ‘¤ Face Detection: Locate faces in images")
    print("   ğŸ“Š Face Attributes: Age, gender, emotion, accessories")
    print("   ğŸ“ Face Landmarks: 27-point facial feature coordinates")
    print("   ğŸ”’ Privacy: Face detection â‰  face recognition")
    print("   âš–ï¸ Compliance: Follow responsible AI guidelines")


def show_ai102_tips():
    """Show AI-102 exam tips"""
    print("\nğŸ“š AI-102 EXAM TIPS")
    print("=" * 60)
    print("\nğŸ¯ IMAGE ANALYSIS:")
    print("   â€¢ Know the difference between v3.2 and v4.0 APIs")
    print("   â€¢ Understand confidence thresholds (default 0.5)")
    print("   â€¢ Memorize visual feature types: Categories, Tags, Description, etc.")
    print("   â€¢ Practice bounding box coordinate interpretation")
    
    print("\nğŸ“– OCR:")
    print("   â€¢ Read API vs Computer Vision OCR - know when to use each")
    print("   â€¢ Understand async operations for large documents")
    print("   â€¢ Know language support limitations")
    print("   â€¢ Practice polygon coordinate systems")
    
    print("\nğŸ‘¤ FACE API:")
    print("   â€¢ Face detection vs face recognition licensing")
    print("   â€¢ Understand emotion detection capabilities")
    print("   â€¢ Know privacy and compliance requirements")
    print("   â€¢ Practice face attribute interpretation")
    
    print("\nâš¡ GENERAL:")
    print("   â€¢ Understand service limits and pricing tiers")
    print("   â€¢ Know regional availability for different versions")
    print("   â€¢ Practice error handling and status codes")
    print("   â€¢ Understand when to use batch vs single operations")


def show_integration_story():
    """Show how services integrate"""
    print("\nğŸ”— INTEGRATION STORY")
    print("=" * 60)
    print("\nğŸ¢ Smart Office Security System:")
    print("   ")
    print("   ğŸ“¹ Step 1: Camera captures visitor at entrance")
    print("   ğŸ” Step 2: Image Analysis identifies 'person' in lobby")
    print("   ğŸ“‹ Step 3: OCR reads visitor badge information")
    print("   ğŸ‘¤ Step 4: Face Analysis confirms human presence")
    print("   âœ… Step 5: System grants/denies access based on analysis")
    print("   ")
    print("   ğŸ’¡ All three services work together for comprehensive security!")


def show_face_setup_guide():
    """Show complete Azure setup instructions"""
    print("\nğŸ› ï¸ COMPLETE AZURE SETUP GUIDE")
    print("=" * 60)
    print("\nğŸ“‹ This demo requires three Azure AI services:")
    print("   ")
    print("   ğŸ” Computer Vision - Image Analysis + OCR")
    print("   ğŸ‘¤ Face API - Face detection and attributes")
    print("   ğŸ“ Same resource group and region for all services")
    print("   ")
    print("   ğŸ“š Complete setup instructions with Microsoft Learn exercises:")
    print("   ğŸ‘‰ See DEMO_GUIDE.md - 'COMPLETE AZURE SETUP GUIDE' section")
    print("   ")
    print("   âš¡ Quick Setup Summary:")
    print("   1. Create resource group: 'ai102-vision-rg'")
    print("   2. Create Computer Vision resource (East US recommended)")
    print("   3. Create Face API resource (same region)")
    print("   4. Copy endpoints and keys to .env file")
    print("   5. Install dependencies: pip install -r requirements.txt")
    print("   6. Test: python demo.py all")
    print("   ")
    print("   âœ… Demo auto-detects services and shows status!")
    print("   ğŸ’¡ Follow Microsoft Learn exercises for detailed walkthrough")


def main():
    """Main demo function with auto-detection"""
    if len(sys.argv) < 2:
        face_status = "âœ… REAL API" if check_face_api_available() else "ğŸ“š EDUCATIONAL"
        
        print("AI-102 Azure Vision Demo")
        print(f"\nFace API Status: {face_status}")
        print("\nUsage: python demo.py <mode>")
        print("\nModes:")
        print("  all      - Complete demo (recommended)")
        print("  image    - Image analysis only")
        print("  ocr      - Text extraction only")
        print("  faces    - Face analysis (auto-detects API)")
        print("  tips     - AI-102 exam tips")
        print("  story    - Integration story")
        print("  setup    - Complete Azure setup guide")
        print("\nExample: python demo.py all")
        print("\nğŸ’¡ Need Azure setup? See DEMO_GUIDE.md or run: python demo.py setup")
        return
    
    print_header()
    mode = sys.argv[1].lower()
    
    try:
        if mode == "all":
            face_mode = "real Face API" if check_face_api_available() else "educational mode"
            print(f"\nğŸ¬ Running complete AI-102 demo with {face_mode}...")
            demo_image_analysis()
            demo_ocr()
            demo_face_analysis()
            show_integration_story()
            
        elif mode == "image":
            demo_image_analysis()
            
        elif mode == "ocr":
            demo_ocr()
            
        elif mode == "faces":
            demo_face_analysis()
            
        elif mode == "tips":
            show_ai102_tips()
            
        elif mode == "story":
            show_integration_story()
            
        elif mode == "setup":
            show_face_setup_guide()
            
        else:
            print(f"âŒ Unknown mode: {mode}")
            print("Run 'python demo.py' for usage information")
            return
            
        print("\n" + "=" * 80)
        print("ğŸ¯ Demo complete! Ready for your AI-102 exam! ğŸš€")
        print("=" * 80)
        
    except Exception as e:
        print(f"\nâŒ Demo error: {str(e)}")
        print("ğŸ’¡ Run 'python test_credentials.py' to check your Azure setup")


if __name__ == "__main__":
    main()
